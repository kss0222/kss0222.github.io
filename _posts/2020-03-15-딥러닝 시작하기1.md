---
layout: post
title:  "딥러닝 시작하기 1"
date:   2020-03-25
author: SeongShin.K
categories: 기계학습및실습
tags: 딥러닝
---


아나콘다(Anaconda)및 텐서플로우(tensoflow) 


> 아나콘다(Anaconda)는 수학과 과학 분야에서 사용되는 여러 패키지들을 묶어 놓은 파이썬 배포판으로서 SciPy, Numpy, Matplotlib, Pandas 등을 비롯한 많은 패키지들을 포함하고 있다. 텐서플로(TensorFlow)는 구글(Google)에서 만든, 딥러닝 프로그램을 쉽게 구현할 수 있도록 다양한 기능을 제공해주는 라이브러리이다.

##  1. 환경 설정
---
<b>1) 가상환경 Anaconda 설치</b>

* Anaconda를 설치하기 위해서는 [Anaconda]( https://www.anaconda.com/) 에서 자신의 OS에 맞는 프로그램을 다운받아 설치하면 된다. 

윈도우 버전은 [여기](https://repo.continuum.io/archive/Anaconda3-4.2.0-Windows-x86_64.exe) 에서 다운


<b>2) 텐서플로우(Tensorflow) 설치</b>
텐서플로우를 새로 만든 가상환경에 설치.(Anaconda Prompt에서 실행)

conda install tensorflow <br>  
<img src = "/assets/Anaconda_install.png">

<b>3) 주피터노트북(Jupyter notebook) 설치 및 실행</b>

conda install jupyter notebook

jupyter notebook

<img src = "/assets/jupyter.png">

자세한 설치 과정은 [여기](https://tensorflow.blog/윈도우즈에-아나콘다-텐서플로우-설치하기/)를 참고.

## 2. Colab 사용하기
--
### Colab 사용법 

구글 지메일 계정으로 로그인
http://colab.research.google.com/ 접속
파일 > 새 python 3 노트 

### GPU 사용하기
: 런타임 유형을 변경
런타임 > 런타임 유형 변경 > 하드웨어 가속기 설정 – GPU 명령으로 GPU 사양 확인

### 구글 드라이브 연동
```python
from google.colab import drive
drive.mount('/content/gdrive')
``` 
URL 링크 > 인증키 확인 > Colab 에 입력

test_colab 폴더 생성 및 확인
```python
!mkdir -p '/content/drive/My Drive/test_colab'
!ls -Fcal '/content/drive/My Drive/test_colab'
``` 
위 폴더에 df.csv파일 만들어서 행렬 저장 
```python
import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.rand(10, 5))
df.to_csv("/content/drive/My Drive/test_colab/df.csv")
``` 
## 3. 딥러닝 관련 파이썬 기초 문법
---

### MNIST 데이터 불러오기 

```python
mnist = tf.keras.datasets.mnist
(image_train, label_train), (image_test, label_test) = mnist.load_data()
```

* 불러온 데이터셋의 shape를 확인해 봅니다. 

```python
image_train.shape, label_train.shape, image_test.shape, label_test.shape
```
((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))

### MNIST 이미지 그리기

```python
import matplotlib.pyplot as plt

size = 5

plt.figure(figsize=(1.5*size,1.5*size))
for i in range(size*size):
  plt.subplot(size,size,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.xlabel(label_train[i])
  plt.imshow(image_train[i])
plt.show()
```
![02]({{ site.url }}/assets/dnn-MNIST.PNG)
### 데이터 Reshape 및 정규화 

* 여기까진 지난 시간에 했던 DNN노트와 다른 점이 없습니다. 하지만 Reshape 할때 shape가 달라집니다. 
Dense layer에 Input으로 들어갈 땐 데이터의 shape이 1차원 벡터지만 Convolution layer에서는 3차원 (이미지가로, 이미지세로, 채널 수 )
가 됩니다. MNIST 데이터는 28, 28 크기의 이미지이고 채널 수는 1 이기 때문에 (28,28,1)로 데이터를 reshape 해주겠습니다. 

```python
# 채널 차원 추가
x_train = image_train.reshape(image_train.shape[0],image_train.shape[1],image_train.shape[2],1).astype('float32')
x_test  = image_test.reshape(image_test.shape[0], image_test.shape[1], image_test.shape[2], 1).astype('float32')

y_train = label_train.reshape(label_train.shape[0], 1)
y_test = label_test.reshape(label_test.shape[0], 1)

# 이미지셋 정규화
x_train, x_test = x_train / 255.0, x_test / 255.0
```

* train data에서 validation data를 따로 분리해 줍시다. 

```python
import sklearn
from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)
```

* 데이터의 차원을 다시 한번 확인해 봅시다. 

```python
x_test_shape = x_test.shape
x_train_shape = x_train.shape
x_val_shape = x_val.shape

print('train:',x_train_shape)
print('val:',x_val_shape)
print('test:',x_test_shape)
```
train: (54000, 28, 28, 1)
val: (6000, 28, 28, 1)
test: (10000, 28, 28, 1)


## 3. 모델 Development
---

* 한 층의 Convolutional layer 후에 Flatten을 하는 아주 간단한 모델을 만들었습니다. 기호(?) 에 맞게 모델을 커스텀하여도 좋습니다. 하지만 MNSIT 데이터는 이 정도 모델 만으로도 우수한 성능을 도출 할 수 있습니다. 

```python
from tensorflow.keras import Model
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, Activation, BatchNormalization

def make_cnn_model():

    model = tf.keras.Sequential()

    model.add(Input(shape=(28,28,1)))

    model.add(Conv2D(64, (5, 5), strides=(2, 2)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))  
    
    model.add(Flatten())
    
    model.add(Dense(128))
    model.add(BatchNormalization())
    model.add(Activation('relu'))  

    model.add(Dense(10))
    model.add(Activation('softmax'))  

    return model

cnn = make_cnn_model()
cnn.summary()
```
![02]({{ site.url }}/assets/cnn-summary.PNG)

## 3. 모델 학습
---

* Model.compile() 함수를 이용해 loss, optimizer, metircs를 정의합니다.

```python

cnn.compile(
  loss='sparse_categorical_crossentropy',
  optimizer='adam',
  metrics=['acc']
)

cnn.fit(
    x_train, y_train, 
    validation_data = (x_val, y_val),
    epochs=5,
)
```

![02]({{ site.url }}/assets/cnn-training.PNG)

* 5번의 epoch로도 98프로가 넘는 accuracy가 나옵니다. 지난시간에 Dense layer 로만 만들었던 모델과 비교하면 훨씬 좋은 성능을 보이는 걸 알 수 있습니다. 

## 4. 모델 확인
---

* Test set을 예측해 보고 그려봅시다.

```python
y_pred = cnn.predict(x_test)
y_pred.shape
```
(10000, 10)

```python
size = 7

plt.figure(figsize=(1.5*size,1.5*size))
for i in range(size*size):
